---
title: "Introduction to Machine Learning"
author: "Jae Yeon Kim"
institute: "UC Berkeley"
date: "`r Sys.Date()`"
---

# Overview

-   The rise of high-dimensional data (e.g., text, image, etc.).

-   The rise of the new approach: statistics + computer science = machine learning

-   Statistical inference

    -   $y$ \<- some probability models (e.g., linear regression, logistic regression) \<- $x$

    -   $y$ = $X\beta$ + $\epsilon$

    -   The goal is to estimate $\beta$

-   Machine learning

    -   $y$ \<- unknown \<- $x$

    -   $y$ \<-\> decision trees, neutral nets \<-\> $x$

    -   For the main idea behind prediction modeling, see Breiman, Leo (Berkeley stat faculty who passed away in 2005). ["Statistical modeling: The two cultures (with comments and a rejoinder by the author)."](https://projecteuclid.org/euclid.ss/1009213726) *Statistical science* 16, no. 3 (2001): 199-231.

    -   "The problem is to find an algorithm $f(x)$ such that for future $x$ in a test set, $f(x)$ will be a good predictor of $y$."

    -   "There are **two cultures** in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a **given** **stochastic data model**. The other uses **algorithmic models** and treats the data mechanism as **unknown**."

-   How ML differs from econometrics?

-   A review by Athey, Susan, and Guido W. Imbens. ["Machine learning methods that economists should know about."](https://www.annualreviews.org/doi/full/10.1146/annurev-economics-080217-053433) *Annual Review of Economics* 11 (2019): 685-725.

-   Stat:

    -   Specifying a target (i.e., an estimand)

    -   Fitting a model to data using an objective function (e.g., the sum of squared errors)

    -   Reporting point estimates (effect size) and standard errors (uncertainty)

    -   Validation by yes-no using goodness-of-fit tests and residual examination

-   ML:

    -   Developing algorithms (estimating *f(x)*)

    -   Prediction power, not structural/causal parameters

    -   Basically, high-dimensional data statistics (N \< P)

    -   The major problem is to avoid ["the curse of dimensionality"](https://en.wikipedia.org/wiki/Curse_of_dimensionality) ([too many features - \> overfitting](https://towardsdatascience.com/the-curse-of-dimensionality-50dc6e49aa1e))

    -   Validation: out-of-sample comparisons (cross-validation) not in-sample goodness-of-fit measures

    -   So, it's curve-fitting, but the primary focus is unseen (test data), not seen data (training data)

-   A quick review on ML lingos for those trained in econometrics

    -   Sample to estimate parameters = Training sample

    -   Estimating the model = Being trained

    -   Regressors, covariates, or predictors = Features

    -   Regression parameters = weights

    -   Prediction problems = Supervised (some $y$ are known) + Unsupervised ($y$ unknown)

![How to teach machines. Based on [vas3k blog](https://vas3k.com/blog/machine_learning/). Many images in this chapter come from vas3k blog.](https://i.vas3k.ru/7w9.jpg)

![The main types of machine learning. Based on [vas3k blog](https://vas3k.com/blog/machine_learning/)](https://i.vas3k.ru/7vz.jpg)

![The map of the machine learning universe. Based on [vas3k blog](https://vas3k.com/blog/machine_learning/)](https://i.vas3k.ru/7vx.jpg)

![Classical machine learning. Based on [vas3k blog](https://vas3k.com/blog/machine_learning/)](https://i.vas3k.ru/7w1.jpg)

# Dataset

-   [Spam dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset).

> A set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged according being ham (legitimate) or spam.

```{r}
# Load packages 

## CRAN packages 
pacman::p_load(here,
               tidyverse, 
               tidymodels, # tidymodels framework 
               janitor, # cleaning data 
               textrecipes, # text recipe 
               themis, # extra recipe 
               doParallel, # parallel processing 
               patchwork) # arranging ggplots
```

```{r include=FALSE}
## Jae's custom functions 
source(here("functions", "ml_utils.r"))

theme_set(theme_minimal())

# Import the dataset 

original <- read_csv(here("lecture_notes", "week11", "spam.csv"))[,1:2]

glimpse(original)

# Create a copy 
df <- original
```

# tidymodels

-   Like `tidyverse`, `tidymodels` is a collection of packages.

    -   [`rsample`](https://rsample.tidymodels.org/): for data splitting

    -   [`recipes`](https://recipes.tidymodels.org/index.html): for pre-processing

    -   [`parsnip`](https://www.tidyverse.org/blog/2018/11/parsnip-0-0-1/): for model building

        -   [`tune`](https://github.com/tidymodels/tune): hyperparameter tuning

    -   [`yardstick`](https://github.com/tidymodels/yardstick): for model evaluations

    -   [`workflows`](https://github.com/tidymodels/workflows): for bundling a pieplne that bundles together preprocessing, modeling, and post-processing requests

-   Why taking a tidyverse approach to machine learning?

-   Benefits

    -   Readable code 

    -   Reusable data structures 

    -   Extendable code 

![Tidymodels. From RStudio.](https://rviews.rstudio.com/post/2019-06-14-a-gentle-intro-to-tidymodels_files/figure-html/ds.png)

> tidymodels are an **integrated, modular, extensible** set of packages that implement a framework that facilitates creating predicative stochastic models. - Joseph [Rickert\@RStudio](mailto:Rickert@RStudio){.email}

-   Currently, 238 models are [available](https://topepo.github.io/caret/available-models.html)

-   The following materials are based on [the machine learning with tidymodels workshop](https://github.com/dlab-berkeley/Machine-Learning-with-tidymodels) I developed for D-Lab. [The original workshop](https://github.com/dlab-berkeley/Machine-Learning-in-R) was designed by [Chris Kennedy](https://ck37.com/) and [Evan Muzzall](<https://dlab.berkeley.edu/people/evan-muzzall>.

# Pre-processing

-   [`recipes`](https://recipes.tidymodels.org/index.html): for pre-processing

-   [`textrecipes`](https://github.com/tidymodels/textrecipes) for text pre-processing

-   Step 1: `recipe()` defines target and predictor variables (ingredients).

-   Step 2: `step_*()` defines preprocessing steps to be taken (recipe).

    The preprocessing steps list draws on the vignette of the [`parsnip`](https://www.tidymodels.org/find/parsnip/) package.

    -   dummy: Also called one-hot encoding

    -   zero variance: Removing columns (or features) with a single unique value

    -   impute: Imputing missing values

    -   decorrelate: Mitigating correlated predictors (e.g., principal component analysis)

    -   normalize: Centering and/or scaling predictors (e.g., log scaling). Scaling matters because many algorithms (e.g., lasso) are scale-variant (except tree-based algorithms). Remind you that normalization (sensitive to outliers) = $\frac{X - X_{min}}{X_{max} - X_{min}}$ and standardization (not sensitive to outliers) = $\frac{X - \mu}{\sigma}$

    -   transform: Making predictors symmetric

-   Step 3: `prep()` prepares a dataset to base each step on.

-   Step 4: `bake()` applies the preprocessing steps to your datasets.

```{r}
names(df) <- c("category", "text")

# The outcome classes are balanced or not?
df %>% janitor::tabyl(category) 

# Factorize the outcome 
df$category <- as.factor(if_else(df$category == "spam", 1, 0))
```

```{r}
rec <- recipe(category ~ text, data = df) %>%
  # Upsample minority class
  step_upsample(category, over_ratio = 0.2) %>% # The current ratio: 747/4825
  # Use bigrams
  step_tokenize(text, token = "ngrams", options = list(n = 2)) %>%
  # Remove stopwords 
  step_stopwords(text) %>%
  # Filter tokens
  step_tokenfilter(text, max_tokens = 1000) %>%
  # Normalize document length
  step_tfidf(text) %>%
  prep()
```

# Split data

```{r}
# for reproducibility 
set.seed(1234)

# split (stratified random sampling)
split_class <- initial_split(df, 
                             strata = category, 
                             prop = 0.7) # Training: 70%, Test: 30%

# training set 
raw_train_class <- training(split_class)
raw_test_class <- testing(split_class)

raw_train_class
```


```{r}
# x features (predictors)
train_x_class <- bake(rec, # recipe  
                      raw_train_class, all_predictors())
test_x_class <- bake(rec, 
                     raw_test_class, all_predictors())

# y outcomes (outcomes)
train_y_class <- bake(rec, 
                      raw_train_class, all_outcomes())$category 
test_y_class <- bake(rec, raw_test_class, all_outcomes())$category

# Can you guess what's the number of features? Remember how we did feature engineering.
ncol(train_x_class)

# What's the type of the outcome variable
class(train_y_class)

# Export data 
save(df, rec, train_x_class, test_x_class, train_y_class, test_y_class,
     file = here(here("lecture_notes", "week11", "stuff.Rdata")))
```
