{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping - Lecture Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Task:\n",
    "\n",
    "Gather information Illinois' elected state legislators here: http://www.ilga.gov/senate/default.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tools:\n",
    "\n",
    "1. [Requests](http://docs.python-requests.org/en/latest/user/quickstart/)\n",
    "2. [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Make a Get Request and Read in HTML\n",
    "\n",
    "We use `requests` library to:\n",
    "1. make a GET request to the page\n",
    "2. read in the html of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp')\n",
    "# read the content of the server’s response\n",
    "src = req.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Soup it\n",
    "\n",
    "Now we use the `BeautifulSoup` function to parse the reponse into an HTML tree. This returns an object (called a **soup object**) which contains all of the HTML in the original document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   Illinois General Assembly - Senate Members\n",
      "  </title>\n",
      "  <link href=\"/style/lis.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <link href=\"/style/print.css\" media=\"print\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <link href=\"http://info.er.usgs.gov/public/gils/gilsexec.html\" rel=\"GILS\"/>\n",
      "  <link href=\"/LISlogo1.ico\" rel=\"Shortcut Icon\"/>\n",
      "  <script language=\"JavaScript\" type=\"text/javascript\">\n",
      "   <!--\n",
      "\n",
      "if(window.event + \"\" == \"undefined\") event = null;\n",
      "function HM_f_PopUp(){return false};\n",
      "function HM_f_PopDown(){return false};\n",
      "popUp = HM_f_PopUp;\n",
      "popDown = HM_f_PopDown;\n",
      "\n",
      "//-->\n",
      "  </script>\n",
      "  <!--\r\n",
      "    option explicit\r\n",
      "  -->\n",
      "  <meta content='(PICS-1.1 \"http://www.weburbia.com/safe/ratings.htm\" l r (s 0))' http-equiv=\"PICS-Label\"/>\n",
      "  <meta content=\"Government\" name=\"classification\"/>\n",
      "  <meta content=\"Global\" name=\"distribution\"/>\n",
      "  <meta content=\"General\" name=\"rating\"/>\n",
      "  <meta content=\"IL\" name=\"contactState\"/>\n",
      "  <meta content=\"Illinois General Assembly\" name=\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachel/anaconda/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /Users/rachel/anaconda/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# parse the response into an HTML tree\n",
    "soup = BeautifulSoup(src)\n",
    "# take a look\n",
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Find Elements\n",
    "\n",
    "BeautifulSoup has a number of functions to find things on a page. Like other webscraping tools, Beautiful Soup lets you find elements by their:\n",
    "\n",
    "1. HTML tags\n",
    "2. HTML Attributes\n",
    "3. CSS Selectors\n",
    "\n",
    "\n",
    "Let's search first for **HTML tags**. \n",
    "\n",
    "The function `find_all` searches the `soup` tree to find all the elements with an a particular HTML tag, and returns all of those elements.\n",
    "\n",
    "What does the example below do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find all elements in a certain tag\n",
    "# these two lines of code are equivilant\n",
    "\n",
    "# soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: Because `find_all()` is the most popular method in the Beautiful Soup search API, you can use a shortcut for it. If you treat the BeautifulSoup object as though it were a function, then it’s the same as calling `find_all()` on that object. These two lines of code are equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# soup.find_all(\"a\")\n",
    "# soup(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot! Many elements on a page will have the same html tag. For instance, if you search for everything with the `a` tag, you're likely to get a lot of stuff, much of which you don't want. What if we wanted to search for HTML tags ONLY with certain attributes, like particular CSS classes? \n",
    "\n",
    "We can do this by adding an additional argument to the `find_all`\n",
    "\n",
    "In the example below, we are finding all the `a` tags, and then filtering those with `class = \"sidemenu\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sidemenu\" href=\"/senate/default.asp\">  Members  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/committees/default.asp\">  Committees  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/schedules/default.asp\">  Schedules  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/journals/default.asp\">  Journals  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/transcripts/default.asp\">  Transcripts  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/rules.asp\">  Rules  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senateaudvid.asp\">  Live Audio/Video  </a>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the 'a' tags in 'sidemenu' class\n",
    "soup(\"a\", class_=\"sidemenu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes a more efficient way to search and find things on a website is by **CSS selector.** For this we have to use a different method, `select()`. Just pass a string into the `.select()` to get all elements with that string as a valid CSS selector.\n",
    "\n",
    "In the example above, we can use \"a.sidemenu\" as a CSS selector, which returns all `a` tags with class `sidemenu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sidemenu\" href=\"/senate/default.asp\">  Members  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/committees/default.asp\">  Committees  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/schedules/default.asp\">  Schedules  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/journals/default.asp\">  Journals  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/transcripts/default.asp\">  Transcripts  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/rules.asp\">  Rules  </a>,\n",
       " <a class=\"sidemenu\" href=\"/senateaudvid.asp\">  Live Audio/Video  </a>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get elements with \"a.sidemenu\" CSS Selector.\n",
    "soup.select(\"a.sidemenu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Get Attributes and Text of Elements\n",
    "\n",
    "Once we identify elements, we want the access information in that element. Oftentimes this means two things:\n",
    "\n",
    "1. Text\n",
    "2. Attributes\n",
    "\n",
    "Getting the text inside an element is easy. All we have to do is use the `text` member of a `tag` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a list\n",
    "soup.select(\"a.sidemenu\")\n",
    "\n",
    "# we first want to get an individual tag object\n",
    "first_link = soup.select(\"a.sidemenu\")[0]\n",
    "\n",
    "# check out its class\n",
    "type(first_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a tag! Which means it has a `text` member:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Members  \n"
     ]
    }
   ],
   "source": [
    "print(first_link.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want the value of certain attributes. This is particularly relevant for `a` tags, or links, where the `href` attribute tells us where the link goes.\n",
    "\n",
    "You can access a tag’s attributes by treating the tag like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/senate/default.asp\n"
     ]
    }
   ],
   "source": [
    "print(first_link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/default.asp\n",
      "/\n",
      "/legislation/\n",
      "/senate/\n",
      "/house/\n",
      "/mylegislation/\n",
      "/sitemap.asp\n",
      "/senate/default.asp\n",
      "/senate/committees/default.asp\n",
      "/senate/schedules/default.asp\n"
     ]
    }
   ],
   "source": [
    "# Get just the href (url) attribute from the first 10 links\n",
    "for link in soup('a')[:10]:\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Do This.\n",
    "\n",
    "Believe it or not, that's all you need to scrape a website. Let's apply these skills to scrape http://www.ilga.gov/senate/default.asp\n",
    "\n",
    "First, make the get request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachel/anaconda/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /Users/rachel/anaconda/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp')\n",
    "# read the content of the server’s response\n",
    "src = req.text\n",
    "# soup it\n",
    "soup = BeautifulSoup(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to get a list of rows in that table. Rows are identified by the `tr` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tr elements\n",
    "rows = soup.find_all(\"tr\")\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But remember, `find_all` gets all the elements with the `tr` tag. We can use smart CSS selectors to get only the rows we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr>\n",
      " <td bgcolor=\"white\" class=\"detail\" width=\"40%\">\n",
      "  <a href=\"/senate/Senator.asp?GA=100&amp;MemberID=2335\">\n",
      "   Pamela J. Althoff\n",
      "  </a>\n",
      " </td>\n",
      " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">\n",
      "  <a href=\"SenatorBills.asp?MemberID=2335\">\n",
      "   Bills\n",
      "  </a>\n",
      " </td>\n",
      " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">\n",
      "  <a href=\"SenCommittees.asp?MemberID=2335\">\n",
      "   Committees\n",
      "  </a>\n",
      " </td>\n",
      " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">\n",
      "  32\n",
      " </td>\n",
      " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">\n",
      "  R\n",
      " </td>\n",
      "</tr>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# returns every ‘tr tr tr’ css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "print(rows[2].prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `select` method on anything. Let's say we want to find everything with the CSS selector `td.detail` in an item of the list we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a href=\"/senate/Senator.asp?GA=100&amp;MemberID=2335\">Pamela J. Althoff</a></td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?MemberID=2335\">Bills</a></td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?MemberID=2335\">Committees</a></td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">32</td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">R</td>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns every ‘tr tr tr’ css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "\n",
    "# Look at just the third item\n",
    "row = rows[2]\n",
    "\n",
    "# select only those 'td' tags with class 'detail'\n",
    "detailCells = row.select('td.detail')\n",
    "\n",
    "detailCells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, we're interested in the actual **text** of a website, not its tags. Remember, to get the text of an HTML element, use the `text` member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# returns every ‘tr tr tr’ css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "\n",
    "# Look at just the third item\n",
    "row = rows[2]\n",
    "\n",
    "# select only those 'td' tags with class 'detail'\n",
    "detailCells = row.select('td.detail')\n",
    "\n",
    "# Keep only the text in each of those cells\n",
    "rowData = [cell.text for cell in detailCells]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine the beautifulsoup tools with our basic python skills to scrape an entire web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pamela J. Althoff\n",
      "32\n",
      "R\n"
     ]
    }
   ],
   "source": [
    "# returns every ‘tr tr tr’ css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "\n",
    "# Look at just the third item\n",
    "row = rows[2]\n",
    "\n",
    "# select only those 'td' tags with class 'detail'\n",
    "detailCells = row.select('td.detail')\n",
    "\n",
    "# Keep only the text in each of those cells\n",
    "rowData = [cell.text for cell in detailCells]\n",
    "\n",
    "# check em out\n",
    "print(rowData[0]) # Name\n",
    "print(rowData[3]) # district\n",
    "print(rowData[4]) # party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a for loop to get 'em all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create empty list to store our data\n",
    "members = []\n",
    "\n",
    "# returns every ‘tr tr tr’ css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "\n",
    "# loop through all rows\n",
    "for row in rows:\n",
    "    # select only those 'td' tags with class 'detail'\n",
    "    detailCells = row.select('td.detail')\n",
    "    \n",
    "    # get rid of junk rows\n",
    "    if len(detailCells) is not 5: \n",
    "        continue\n",
    "        \n",
    "    # Keep only the text in each of those cells\n",
    "    rowData = [cell.text for cell in detailCells]\n",
    "    \n",
    "    # Collect information\n",
    "    name = rowData[0]\n",
    "    district = int(rowData[3])\n",
    "    party = rowData[4]\n",
    "    \n",
    "    # Store in a tuple\n",
    "    tup = (name,district,party)\n",
    "    \n",
    "    # Append to list\n",
    "    members.append(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1\n",
    "\n",
    "Make a function that accepts a URL, scrapes the URL for its senators, and returns a list of tuples containing information about each senator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_members(url):\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test you code!\n",
    "\n",
    "# get_members('http://www.ilga.gov/senate/default.asp?GA=98')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Challenge 2\n",
    "\n",
    "Given the `senateMembers`  list, create a new dictionary `members_dict` which has as its keys the district number (e.g. ` 32`) and as its values, the entire tuple as returned by `get_members()` (name, district number, party, url). We can do this because the district number is a unique identifier for each senator.\n",
    "\n",
    "Calling `members_dict[32]`, for example, should return the 4-tuple:\n",
    "\n",
    "```(u'Pamela J. Althoff',\n",
    "32,\n",
    "u'R',\n",
    "'http://www.ilga.gov/senate/SenatorBills.asp?GA=98&MemberID=1911&Primary=True')\n",
    "```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `find_all` not found.\n"
     ]
    }
   ],
   "source": [
    "? find_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
